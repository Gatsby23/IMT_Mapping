# Sequence parameters
sequence_type: "icl_nuim.ICLNUIMSequence"

dataset_type: "replica"
scene: "office0"
use_gt: False
pose_folder: "./treasure/orbslam2_record/imap_office0/"
outdir: "./res/replica_office0_ours/"

calib: [600., 600., 599.5, 339.5, 6553.5]

sequence_kwargs:
  path: "./data/replica/office0"
  start_frame: 0
  end_frame: -1                                       # Run all frames
  #first_tq: [-1.2, 1.3, 1.0, 0.0, -1.0, 0.0, 0.0]     # Starting pose
  first_tq: [0, 0, 0.0, 0.0, -1.0, 0.0, 0.0] 

# Network parameters (network structure, etc. will be inherited from the training config)
training_hypers: "./treasure/hyper.json"
using_epoch: 600

# Separate tracking and meshing.
run_async: false
# Enable visualization
vis: false
resolution: 3

# These two define the range of depth observations to be cropped. Unit is meter.
depth_cut_min: 0.5
depth_cut_max: 5.0

meshing_interval: 20
integrate_interval: 20

# Mapping parameters
mapping:
  # Bound of the scene to be reconstructed
  bound_min: [-10.5, -5.5, -10.]
  bound_max: [10.5, 5.5, 10.5]
 
  voxel_size: 0.1
  # Prune observations if detected as noise.
  prune_min_vox_obs: 16
  ignore_count_th: 16.0
  encoder_count_th: 600.0

# Tracking parameters
tracking:
  # An array defining how the camera pose is optimized.
  # Each element is a dictionary:
  #   For example {"n": 2, "type": [['sdf'], ['rgb', 1]]} means to optimize the summation of sdf term and rgb term
  # at the 1st level pyramid for 2 iterations.
  iter_config:
    - {"n": 10, "type": [['sdf'], ['rgb', 1]]}
    - {"n": 50, "type": [['sdf'], ['rgb', 0]]}
  sdf:
    robust_kernel: "huber"
    robust_k: 5.0
    subsample: 0.5
  rgb:
    weight: 50.0
    robust_kernel: null
    robust_k: 0.01
    min_grad_scale: 0.0
    max_depth_delta: 0.2
